str(training2)
training2<-training[, grep("/IL", colnames(training))]
str(training2)
training2<-training[, -13]
str(training2)
training2<-training[, grep("IL", colnames(training))]
training2<-training2[, -13]
str(training2)
PCA<-prcomp(training2)
spreeplot(PCA)
summary(PCA)
str(training)
str(trainig2)
str(training2)
?preProcess
preProc<-preProcess(log10(training)+1),method="pca",pcaComp=5)
preProc<-preProcess(log10(training)+1),method="pca",pcaComp=2)
preProc<-preProcess(log10(training),method="pca",pcaComp=2)
preProc<-preProcess(log10(training+1),method="pca",pcaComp=2)
training2$diagnosis<-training$diagnosis
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2<-training[, grep("IL", colnames(training))]
training2<-training2[, -13]
?preProcess
model1<-preProcess(training2,method="pca")
model1
summary(model1)
model1<-preProcess(training2,method="pca", thresh=0.8)
model1
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
model1<-preProcess(training2,method="pca",thresh=0.8)
training3<-predict(model1,training2)
summary(training2)
summary(training3)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
model1<-preProcess(training2,method="pca",thresh=0.8)
training3<-predict(model1,training2)
training2$diagnosis<-training$diagnosis
training3$diagnosis<-training$diagnosis
lm1<-train(diagnosis~., data=training2,method="lm")
summary(lm1$finalModel)
pred1<-pred(lm1,testing)
lm2<-train(diagnosis~.,data=training3,method="lm")
summary(lm2$finalModel)
pred2<-predict(lm2,data=testing)
str(training2)
summary(training2$diagnosis)
lm1<-train(diagnosis~., data=training2,method="glm")
summary(lm1$finalModel)
pred1<-pred(lm1,testing)
pred1<-predict(lm1,testing)
lm2<-train(diagnosis~.,data=training3,method="glm")
summary(lm2$finalModel)
pred2<-predict(lm2,data=testing)
pred1<-predict(lm1,testing)
confusionMatrix(pred1,testing$diagnosis)
lm2<-train(diagnosis~.,data=training3,method="glm")
summary(lm2$finalModel)
pred2<-predict(lm2,data=testing)
summary(lm2$finalModel)
training2<-training[, grep("IL", colnames(training))]
training2<-training2[, -13]
M<-abs(cor(training))
diag(M)<-0
which(M>0.8,arr.ind=T)
str(training2)
M<-abs(cor(training))
preProc<-preProcess(training2,method="pca",thresh=0.8)
trainPCA<-predict(preProc,training)
lm2<-train(diagnosis~.,data=training3,method="glm", preProcess="pca")
summary(lm2$finalModel)
confusionMatrix(testing$diagnosis,predict(lm2,testing))
confusionMatrix(testing$diagnosis,predict(lm2,testing))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2<-training[, grep("IL", colnames(training))]
training2<-training2[, -13]
model1<-preProcess(training2,method="pca",thresh=0.8)
model1
##Exercise 3 Week 2
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
##
training2<-training[, grep("IL", colnames(training))]
training2<-training2[, -13]
##
training2$diagnosis<-training$diagnosis
training3$diagnosis<-training$diagnosis
lm1<-train(diagnosis~., data=training2,method="glm")
summary(lm1$finalModel)
pred1<-predict(lm1,testing)
confusionMatrix(pred1,testing$diagnosis)
lm2<-train(diagnosis~.,data=training3,method="glm", preProcess="pca")
summary(lm2$finalModel)
confusionMatrix(testing$diagnosis,predict(lm2,testing))
PCA<-prcomp(training2)
summary(PCA)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data1<-data(segmentationOriginal)
str(data1)
library(AppliedPredictiveModeling)
data1<-data(segmentationOriginal)
library(caret)
str(data1)
library(AppliedPredictiveModeling)
library(caret)
data1<-data(segmentationOriginal)
data(segmentationOriginal)
str
str(data)
str(segmentationOriginal)
Samples<-createDataPartition(segmentationOriginal$Case, p = 1/2)
Samples<-createDataPartition(segmentationOriginal$Case, p = 1/2)
training<-segmentationOriginal[ Samples,]
test<-segmentationOriginal[-samples,]
set.seed(125)
training<-segmentationOriginal[Samples,][1]
?subset
library(caTools)
data(segmentationOriginal)
Split<-sample.split(segmentationOriginal$Case, SplitRatio= 0.5)
training<-subset(segmentationOriginal,split==TRUE)
test<-subset(segmentationOriginal, split==FALSE)
set.seed(125)
summary(segmentationOriginal$Case)
segmentationOriginal$Case
class(segmentationOriginal)
summary(segmentationOriginal)
data(segmentationOriginal)
summary(segmentationOriginal)
install.packages("ElemStatLearn")
setInternet2(TRUE)
install.packages("ElemStatLearn")
install.packages("pgmm")
library(AppliedPredictiveModeling)
library(caret)
library(caTools)
data(segmentationOriginal)
set.seed(125)
inTrain<- createDataPartition(y=segmentationOriginal$Case,p=0.5,list=FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain]
modfit<-train(Case ~ ., method="rpart", data =training)
print(modfit$finalModel)
str(training)
modfit<-train(Class ~ ., method="rpart", data =training)
print(modfit$finalModel)
plot(modfit$finalModel,uniform=TRUE)
text(modfit$finalModel,use.n=TRUE,all=TRUE,cex=0.6)
plot(modfit$finalModel,uniform=TRUE)
plot(modfit$finalModel,uniform=TRUE)
text(modfit$finalModel,use.n=TRUE,all=TRUE,cex=0.6)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
modfit3<-train(Area ~., method="rpart", data=olive)
library(AppliedPredictiveModeling)
library(caret)
modfit3<-train(Area ~., method="rpart", data=olive)
predict(modfit3,newdata=newdata)
newdata = as.data.frame(t(colMeans(olive)))
predict(modfit3,newdata=newdata)
newdata
plot(modfit3$finalModel,uniform=TRUE)
text(modfit3$finalModel,use.n=TRUE,all=TRUE,cex=0.6)
str(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
data(SAheart)
library(ElemStatLearn)
data(SAheart)
library(ElemStatLearn)
data(SAheart)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
str(SAheart)
?SAheart
set.seed(13234)
modfit4<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family="binomial")
modfit4<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family="binomial", data=train)
modfit4<-glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, family="binomial", data=train)
?train
modfit4<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family=binomial, data=train)
modfit4<-glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=train, family=binomial)
modfit4<-glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=train, family=binomial)
str(train)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
modfit4<-glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, family=binomial)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missclass(trainSA$chd,modfit4)
missClass(trainSA$chd,modfit4)
missClass(trainSA,modfit4)
modfit4<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family=binomial, data=trainSA)
missClass(trainSA,modfit4)
predTrain<-predict(modfit4,newdata=testSA)
predTest<-predict(modfit4,newdata=testSA)
predTrain<-predict(modfit4,newdata=trainSA)
missClass(trainSA,predTest)
missClass(trainSA,predTrain)
head(predTrain)
head(trainSA$chd)
?predict
missClass(trainSA,predTrain)
missClass(trainSA,predTrain)/length(TrainSA)
missClass(trainSA,predTrain)/length(trainSA)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/nrow(values)}
missClass(trainSA,predTrain)
missClass(trainSA,predTest)
modfit4<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA,method="glm" family=binomial)
modfit4<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA,method="glm", family=binomial)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA,predTest)
missClass(trainSA,predTrain)
predTest<-predict(modfit4,newdata=testSA)
predTrain<-predict(modfit4,newdata=trainSA)
predTest<-predict(modfit4,newdata=testSA)
?class
str(trainSA)
class(predTrain)<-"int"
str(predTrain)
predTest<-predict(modfit4,newdata=testSA)
predTrain<-predict(modfit4,newdata=trainSA)
predTrain<-as.integer(predTrain)
str(predTrain)
predTest<-predict(modfit4,newdata=testSA)
predTrain<-predict(modfit4,newdata=trainSA)
?round
round(predTest,digits=0)
head(predtest,n=10)
head(predTest,n=10)
predTest<-round(predTest,digits=0)
predTrain<-round(predTrain,digits=0)
missClass(trainSA,predTest)
missClass(trainSA,predTrain)
missClass(testSA,predTest)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/nrow(values)}
missClass(trainSA,predTrain)
missClass(testSA,predTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
str(vowel.train)
vowel.train<-as.factor(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
modfit5<-train(y ~ ., data=vowel.train,method="rf",prox=TRUE)
?varImp
varImp(modfit5)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modfit4<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA,method="glm", family=binomial)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/nrow(values)}
predTest<-predict(modfit4,newdata=testSA)
predTrain<-predict(modfit4,newdata=trainSA)
misClass(trainSA$chd,predTrain)
missClass(trainSA$chd,predTrain)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predTrain)
missClass(testSA$chd,predTest)
(1/2)^1
(1/2)^2
(1/2)^4
(1/2)^8
(1/2)^16
(1/2)^32
(1/2)^64
(1/2)^128
(1/2)^128
(1/2)^256
(1/2)^512
(1/2)^1024
(1/2)^129
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
summary(training)
library("randomForest", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("rattle", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("RColorBrewer", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("rpart", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("rpart.plot", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("caret", lib.loc="C:/Program Files/R/R-3.1.2/library")
str(training)
summary(training$classe)
?createDataPartition
colSums(is.na(trainRaw)
)
colSums(is.na(training)
)
colSums(is.na(training)/nrow(training))
table(colSums(is.na(training)/nrow(training)))
library(caret)
library(randomForest)
library(rattle)
library(RColorBrewer)
library(rpart)
library(rpart.plot)
set.seed(151081)
subsetTrain<-createDataPartition(training$classe, p=0.7)
train1<-training[subsetTrain,]
test1<-training[-subsetTrain,]
subsetTrain<-createDataPartition(training$classe, p=0.7, list=FALSE)
train1<-training[subsetTrain,]
test1<-training[-subsetTrain,]
table(colSums(is.na(train1)/nrow(train1)))
#there are only variables with no NAs and variables where most values are NAs;therefore, the threshold is (% of NA ==0)
train1<-train1[,colSums(is.na(train1)/nrow(train1))==0]
nsv <- nearZeroVar(train1, saveMetrics=TRUE)
nsv
nzv
?nzv
nsv
?nsv
summary(nsv)
table(colSums(is.na(train1)/nrow(train1)))
#there are only variables with no NAs and variables where most values are NAs;therefore, the threshold is (% of NA ==0)
train1<-train1[,colSums(is.na(train1)/nrow(train1))==0]
nsv <- nearZeroVar(train1, saveMetrics=TRUE)
summary(nsv)
#There are 34 variables with "near zero variance" as detected by this function, so they will be removed
nsv_col<-rownames(nsv)[nsv$nzv==FALSE]
train1<-train1[,colnames(train1) %in% nsv_col]
str(train1)
train1<-train1[,-1:6]
train1<-train1[,7:53]
train
?train
summary(train1)
DTmodel<-train(classe ~ ., method="rpart", preProcess=c("center","scale"))
DTmodel<-train(classe ~ ., method="rpart", preProcess=c("center","scale"),data=train1)
train1$classe
subsetTrain<-createDataPartition(training$classe, p=0.7, list=FALSE)
train1<-training[subsetTrain,]
test1<-training[-subsetTrain,]
table(colSums(is.na(train1)/nrow(train1)))
#there are only variables with no NAs and variables where most values are NAs;therefore, the threshold is (% of NA ==0)
train1<-train1[,colSums(is.na(train1)/nrow(train1))==0]
nsv <- nearZeroVar(train1, saveMetrics=TRUE)
summary(nsv)
#There are 34 variables with "near zero variance" as detected by this function, so they will be removed
nsv_col<-rownames(nsv)[nsv$nzv==FALSE]
train1<-train1[,colnames(train1) %in% nsv_col]
summary(train1)
train1<-train1[,7:54]
summary(train1)
set.seed(151081)
subsetTrain<-createDataPartition(training$classe, p=0.7, list=FALSE)
train1<-training[subsetTrain,]
test1<-training[-subsetTrain,]
table(colSums(is.na(train1)/nrow(train1)))
#there are only variables with no NAs and variables where most values are NAs;therefore, the threshold is (% of NA ==0)
train1<-train1[,colSums(is.na(train1)/nrow(train1))==0]
nsv <- nearZeroVar(train1, saveMetrics=TRUE)
summary(nsv)
#There are 34 variables with "near zero variance" as detected by this function, so they will be removed
nsv_col<-rownames(nsv)[nsv$nzv==FALSE]
train1<-train1[,colnames(train1) %in% nsv_col]
ncol(train1$classe)
train1$classe
names(train1)
train1<-train1[,7:59]
DTmodel<-train(classe ~ ., method="rpart", preProcess=c("center","scale"),data=train1)
print(DTmodel)
predDT <- predict(DTmodel, newdata=test1)
print(confusionMatrix(predDT, test1$classe))
trControl=trainControl(method = "cv"
DTmodel2<-train(classe ~ ., method="rpart",trControl=trainControl(method = "cv") ,data=train1)
print(DTmodel2)
#run the model on the test set to check the our of sample error
predDT2 <- predict(DTmodel2, newdata=test1)
print(confusionMatrix(predDT2, test1$classe))
DTmodel2<-train(classe ~ ., method="rpart",trControl=trainControl(method = "cv") ,data=train1)
print(DTmodel2)
#run the model on the test set to check the our of sample error
predDT2 <- predict(DTmodel2, newdata=test1)
print(confusionMatrix(predDT2, test1$classe))
DTmodel2<-train(classe ~ ., method="rpart" ,data=train1)
print(DTmodel2)
#run the model on the test set to check the our of sample error
predDT2 <- predict(DTmodel2, newdata=test1)
print(confusionMatrix(predDT2, test1$classe))
DTmodel2<-train(classe ~ ., method="rpart", preProcess=c("center","scale"), trControl=trainControl(method = "cv"), data=train1)
?method
RFmodel<-train(classe ~ ., ntree=300, method="rf", trControl=trainControl(method="cv"), data=train1)
print(RFmodel)
predRF <- predict(RFmodel, test1, type = "class")
predRF <- predict(RFmodel, newdata=test1)
print(confusionMatrix(predRF, test1$classe))
summary(testing)
testing<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", header=TRUE, na.strings=c("NA","#DIV/0!",""))
str(testing)
testing<-testing[,colnames(testing) %in% nsv_col]
result <- predict(modelRf, testing)
result <- predict(RFmodel, testing)
result
oose <- 1 - as.numeric(confusionMatrix(test1$classe, PredRF)$overall[1])
oose <- 1 - as.numeric(confusionMatrix(test1$classe, predRF)$overall[1])
oose
1-0.9905
=1674/1678
1674/1678
1127/1135
1018/1059
1082/1080
1082/1085
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", header=TRUE, na.strings=c("NA","#DIV/0!",""))
getwd()
setwd("D:/2_Formacion personal/N. Coursera/Data Science - Johns Hopkins - Especializacion/08. Predictive Machine Learning/Assignment")
trainingURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingURL<-"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training<-read.csv(trainingURL, header=TRUE, na.strings=c("NA","#DIV/0!",""))
testing<-read.csv(testingURL, header=TRUE, na.strings=c("NA","#DIV/0!",""))
trainingURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingURL<-"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training<-read.csv(trainingURL, header=TRUE, na.strings=c("NA","#DIV/0!",""))
setwd("C:/Users/i.deandres/Downloads")
setwd("C:/testR/MLAssignment")
getwd()
?write.csv
testing<-read.csv(testingURL, header=TRUE, na.strings=c("NA","#DIV/0!",""))
training<-read.csv(trainingURL, header=TRUE, na.strings=c("NA","#DIV/0!",""))
write.csv(training, file="training.csv")
write.csv(testing, file="testing.csv")
training<-read.csv("training.csv")
testing<-read.csv("testing.csv")
set.seed(151081)
subsetTrain<-createDataPartition(training$classe, p=0.7, list=FALSE)
train1<-training[subsetTrain,]
test1<-training[-subsetTrain,]
table(colSums(is.na(train1)/nrow(train1)))
#there are only variables with no NAs and variables where most values are NAs;therefore, the threshold is (% of NA ==0)
train1<-train1[,colSums(is.na(train1)/nrow(train1))==0]
nsv <- nearZeroVar(train1, saveMetrics=TRUE)
summary(nsv)
#There are 34 variables with "near zero variance" as detected by this function, so they will be removed
nsv_col<-rownames(nsv)[nsv$nzv==FALSE]
train1<-train1[,colnames(train1) %in% nsv_col]
testing<-testing[,colnames(testing) %in% nsv_col]
train1<-train1[,7:59]
summary(train1)
set.seed(151081)
subsetTrain<-createDataPartition(training$classe, p=0.7, list=FALSE)
train1<-training[subsetTrain,]
test1<-training[-subsetTrain,]
table(colSums(is.na(train1)/nrow(train1)))
#there are only variables with no NAs and variables where most values are NAs;therefore, the threshold is (% of NA ==0)
train1<-train1[,colSums(is.na(train1)/nrow(train1))==0]
nsv <- nearZeroVar(train1, saveMetrics=TRUE)
summary(nsv)
#There are 34 variables with "near zero variance" as detected by this function, so they will be removed
nsv_col<-rownames(nsv)[nsv$nzv==FALSE]
train1<-train1[,colnames(train1) %in% nsv_col]
testing<-testing[,colnames(testing) %in% nsv_col]
summary(train1)
str(train1)
train1<-train1[,7:60]
summary(train1)
The results are quite poor, so we move the our second option: Random Forest.
